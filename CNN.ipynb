{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we will try to get a general overview of CNNs and what can be done with them.\n",
    "We will use the MNIST dataset.\n",
    "At the end of the notebook as an extra side, you can also try to implement something similar by loading the CIFAR-10 dataset.\n",
    "\n",
    "Please note that this notebook is not an advanced implementation of CNNs. It is just for you to learn ho to implement from scratch a simple CNN, without using any pre-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "The MNIST dataset is a large database of handwritten digits. It contains 60,000 training images and 10,000 testing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the packages that you may need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "#from seansUtils.research import StatsCallback, ModelSummary\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load the MNIST dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Perform some data pre-processing on both input and labels. Hint: reshape the input with dimension (28,28,1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28,1).astype('float32')\n",
    "train_images /=255\n",
    "test_images /=255\n",
    "train_labels = to_categorical(train_labels,10)\n",
    "test_labels = to_categorical(test_labels,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Print the shape of the data and some sample to visualize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- THE DATA ---\n",
      "train_images shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the Data\n",
    "print('--- THE DATA ---')\n",
    "print('train_images shape:', train_images.shape)\n",
    "print(train_images.shape[0], 'train samples')\n",
    "print(test_images.shape[0], 'test samples')\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN\n",
    "\n",
    "This is the most basic CNN: you will have to build a convolutional neural network that is composed by 2 Convolutional layers and 2 Fully Connected layers. Use proper activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Set the number of batches and epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Build the Vanilla CNN model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model_vanilla.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model_vanilla.add(Convolution2D(32, 3, 3))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla.add(Flatten())\n",
    "model_vanilla.add(Dense(128))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# Prediction output Layer\n",
    "model_vanilla.add(Dense(10))\n",
    "model_vanilla.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get a summary of the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 9, 9, 32)          320       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               36992     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 47,850\n",
      "Trainable params: 47,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vanilla.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Configure the model with an optimizer and a loss. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "12000/12000 [==============================] - 19s 2ms/step - loss: 0.3353 - accuracy: 0.8960\n",
      "Epoch 2/64\n",
      "12000/12000 [==============================] - 17s 1ms/step - loss: 0.0855 - accuracy: 0.9739\n",
      "Epoch 3/64\n",
      "12000/12000 [==============================] - 15s 1ms/step - loss: 0.0570 - accuracy: 0.9825\n",
      "Epoch 4/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0464 - accuracy: 0.9853\n",
      "Epoch 5/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0351 - accuracy: 0.9884\n",
      "Epoch 6/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0269 - accuracy: 0.9905\n",
      "Epoch 7/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0251 - accuracy: 0.9917\n",
      "Epoch 8/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 9/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 10/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0159 - accuracy: 0.9943\n",
      "Epoch 11/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0159 - accuracy: 0.9948\n",
      "Epoch 12/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 13/64\n",
      "12000/12000 [==============================] - 18s 1ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "Epoch 14/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 15/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0136 - accuracy: 0.9959\n",
      "Epoch 16/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 17/64\n",
      "12000/12000 [==============================] - 17s 1ms/step - loss: 0.0153 - accuracy: 0.9959\n",
      "Epoch 18/64\n",
      "12000/12000 [==============================] - 17s 1ms/step - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 19/64\n",
      "12000/12000 [==============================] - 15s 1ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 20/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0124 - accuracy: 0.9967\n",
      "Epoch 21/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0148 - accuracy: 0.9963\n",
      "Epoch 22/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 23/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 24/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0111 - accuracy: 0.9973\n",
      "Epoch 25/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0130 - accuracy: 0.9968\n",
      "Epoch 26/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0126 - accuracy: 0.9965\n",
      "Epoch 27/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0113 - accuracy: 0.9976\n",
      "Epoch 28/64\n",
      "12000/12000 [==============================] - 12s 994us/step - loss: 0.0147 - accuracy: 0.9963\n",
      "Epoch 29/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0140 - accuracy: 0.9969\n",
      "Epoch 30/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0125 - accuracy: 0.9976\n",
      "Epoch 31/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0135 - accuracy: 0.9973\n",
      "Epoch 32/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0110 - accuracy: 0.9974\n",
      "Epoch 33/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0124 - accuracy: 0.9972\n",
      "Epoch 34/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0120 - accuracy: 0.9975\n",
      "Epoch 35/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 36/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0099 - accuracy: 0.9979\n",
      "Epoch 37/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0131 - accuracy: 0.9976\n",
      "Epoch 38/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0131 - accuracy: 0.9981\n",
      "Epoch 39/64\n",
      "12000/12000 [==============================] - 12s 979us/step - loss: 0.0156 - accuracy: 0.9971\n",
      "Epoch 40/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0114 - accuracy: 0.9982\n",
      "Epoch 41/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0141 - accuracy: 0.9977\n",
      "Epoch 42/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0149 - accuracy: 0.9975\n",
      "Epoch 43/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0109 - accuracy: 0.9981\n",
      "Epoch 44/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0118 - accuracy: 0.9979\n",
      "Epoch 45/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0132 - accuracy: 0.9979\n",
      "Epoch 46/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0108 - accuracy: 0.9982\n",
      "Epoch 47/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0141 - accuracy: 0.9976\n",
      "Epoch 48/64\n",
      "12000/12000 [==============================] - 12s 995us/step - loss: 0.0118 - accuracy: 0.9979\n",
      "Epoch 49/64\n",
      "12000/12000 [==============================] - 12s 1ms/step - loss: 0.0160 - accuracy: 0.9978\n",
      "Epoch 50/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0164 - accuracy: 0.9975\n",
      "Epoch 51/64\n",
      "12000/12000 [==============================] - 17s 1ms/step - loss: 0.0123 - accuracy: 0.9983\n",
      "Epoch 52/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0196 - accuracy: 0.9975\n",
      "Epoch 53/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0115 - accuracy: 0.9982\n",
      "Epoch 54/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0133 - accuracy: 0.9980\n",
      "Epoch 55/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0094 - accuracy: 0.9984\n",
      "Epoch 56/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0110 - accuracy: 0.9985\n",
      "Epoch 57/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0112 - accuracy: 0.9985\n",
      "Epoch 58/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.0135 - accuracy: 0.9985\n",
      "Epoch 59/64\n",
      "12000/12000 [==============================] - 12s 989us/step - loss: 0.0126 - accuracy: 0.9984\n",
      "Epoch 60/64\n",
      "12000/12000 [==============================] - 12s 985us/step - loss: 0.0144 - accuracy: 0.9981\n",
      "Epoch 61/64\n",
      "12000/12000 [==============================] - 12s 972us/step - loss: 0.0156 - accuracy: 0.9981\n",
      "Epoch 62/64\n",
      "12000/12000 [==============================] - 12s 970us/step - loss: 0.0120 - accuracy: 0.9985\n",
      "Epoch 63/64\n",
      "12000/12000 [==============================] - 12s 974us/step - loss: 0.0134 - accuracy: 0.9984\n",
      "Epoch 64/64\n",
      "12000/12000 [==============================] - 12s 978us/step - loss: 0.0132 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc7d2e1ecd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_vanilla.fit(train_images, train_labels, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Max Pooling and Dropout\n",
    "\n",
    "Let's implement the same CNN as above but plus Max Pooling and Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the new network with max pooling and dropout. You should think a little bit where Max Pooling and Dropout should be inserted. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model_vanilla_pooling.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla_pooling.add(Flatten())\n",
    "model_vanilla_pooling.add(Dense(128))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "    \n",
    "# More Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.5))\n",
    "\n",
    "# Fully Connected Layer for Prediction\n",
    "model_vanilla_pooling.add(Dense(10))\n",
    "model_vanilla_pooling.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get a summary of the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 9, 9, 32)          320       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 15,082\n",
      "Trainable params: 15,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vanilla_pooling.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Configure the network. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train the network. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "12000/12000 [==============================] - 16s 1ms/step - loss: 1.0888 - accuracy: 0.6398\n",
      "Epoch 2/64\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.5602 - accuracy: 0.8291\n",
      "Epoch 3/64\n",
      "12000/12000 [==============================] - 11s 921us/step - loss: 0.4982 - accuracy: 0.8497\n",
      "Epoch 4/64\n",
      "12000/12000 [==============================] - 12s 962us/step - loss: 0.4596 - accuracy: 0.8640\n",
      "Epoch 5/64\n",
      "12000/12000 [==============================] - 12s 965us/step - loss: 0.4218 - accuracy: 0.8701\n",
      "Epoch 6/64\n",
      "12000/12000 [==============================] - 11s 958us/step - loss: 0.4050 - accuracy: 0.8782\n",
      "Epoch 7/64\n",
      "12000/12000 [==============================] - 11s 928us/step - loss: 0.3941 - accuracy: 0.8822\n",
      "Epoch 8/64\n",
      "12000/12000 [==============================] - 11s 936us/step - loss: 0.3795 - accuracy: 0.8881\n",
      "Epoch 9/64\n",
      "12000/12000 [==============================] - 11s 935us/step - loss: 0.3779 - accuracy: 0.8875\n",
      "Epoch 10/64\n",
      "12000/12000 [==============================] - 11s 887us/step - loss: 0.3726 - accuracy: 0.8887\n",
      "Epoch 11/64\n",
      "12000/12000 [==============================] - 11s 948us/step - loss: 0.3702 - accuracy: 0.8909\n",
      "Epoch 12/64\n",
      "12000/12000 [==============================] - 11s 896us/step - loss: 0.3584 - accuracy: 0.8941\n",
      "Epoch 13/64\n",
      "12000/12000 [==============================] - 11s 900us/step - loss: 0.3729 - accuracy: 0.8890\n",
      "Epoch 14/64\n",
      "12000/12000 [==============================] - 11s 915us/step - loss: 0.3564 - accuracy: 0.8939\n",
      "Epoch 15/64\n",
      "12000/12000 [==============================] - 12s 962us/step - loss: 0.3571 - accuracy: 0.8937\n",
      "Epoch 16/64\n",
      "12000/12000 [==============================] - 11s 956us/step - loss: 0.3547 - accuracy: 0.8945\n",
      "Epoch 17/64\n",
      "12000/12000 [==============================] - 12s 967us/step - loss: 0.3451 - accuracy: 0.8967\n",
      "Epoch 18/64\n",
      "12000/12000 [==============================] - 11s 898us/step - loss: 0.3481 - accuracy: 0.8958\n",
      "Epoch 19/64\n",
      "12000/12000 [==============================] - 11s 902us/step - loss: 0.3502 - accuracy: 0.8953\n",
      "Epoch 20/64\n",
      "12000/12000 [==============================] - 11s 898us/step - loss: 0.3423 - accuracy: 0.8980\n",
      "Epoch 21/64\n",
      "12000/12000 [==============================] - 11s 896us/step - loss: 0.3407 - accuracy: 0.8962\n",
      "Epoch 22/64\n",
      "12000/12000 [==============================] - 11s 899us/step - loss: 0.3504 - accuracy: 0.8970\n",
      "Epoch 23/64\n",
      "12000/12000 [==============================] - 11s 897us/step - loss: 0.3403 - accuracy: 0.8980\n",
      "Epoch 24/64\n",
      "12000/12000 [==============================] - 11s 905us/step - loss: 0.3399 - accuracy: 0.8994\n",
      "Epoch 25/64\n",
      "12000/12000 [==============================] - 11s 915us/step - loss: 0.3396 - accuracy: 0.8984\n",
      "Epoch 26/64\n",
      "12000/12000 [==============================] - 11s 917us/step - loss: 0.3389 - accuracy: 0.8973\n",
      "Epoch 27/64\n",
      "12000/12000 [==============================] - 11s 902us/step - loss: 0.3444 - accuracy: 0.8986\n",
      "Epoch 28/64\n",
      "12000/12000 [==============================] - 11s 943us/step - loss: 0.3370 - accuracy: 0.8987\n",
      "Epoch 29/64\n",
      "12000/12000 [==============================] - 12s 998us/step - loss: 0.3429 - accuracy: 0.8964\n",
      "Epoch 30/64\n",
      "12000/12000 [==============================] - 11s 916us/step - loss: 0.3414 - accuracy: 0.8980\n",
      "Epoch 31/64\n",
      "12000/12000 [==============================] - 11s 902us/step - loss: 0.3491 - accuracy: 0.8969\n",
      "Epoch 32/64\n",
      "12000/12000 [==============================] - 11s 900us/step - loss: 0.3354 - accuracy: 0.8988\n",
      "Epoch 33/64\n",
      "12000/12000 [==============================] - 11s 900us/step - loss: 0.3381 - accuracy: 0.8999\n",
      "Epoch 34/64\n",
      "12000/12000 [==============================] - 11s 897us/step - loss: 0.3421 - accuracy: 0.8989\n",
      "Epoch 35/64\n",
      "12000/12000 [==============================] - 11s 897us/step - loss: 0.3415 - accuracy: 0.8989\n",
      "Epoch 36/64\n",
      "12000/12000 [==============================] - 12s 980us/step - loss: 0.3541 - accuracy: 0.8959\n",
      "Epoch 37/64\n",
      "12000/12000 [==============================] - 11s 935us/step - loss: 0.3457 - accuracy: 0.8965\n",
      "Epoch 38/64\n",
      "12000/12000 [==============================] - 11s 923us/step - loss: 0.3373 - accuracy: 0.8999\n",
      "Epoch 39/64\n",
      "12000/12000 [==============================] - 11s 921us/step - loss: 0.3469 - accuracy: 0.8986\n",
      "Epoch 40/64\n",
      "12000/12000 [==============================] - 11s 923us/step - loss: 0.3425 - accuracy: 0.8971\n",
      "Epoch 41/64\n",
      "12000/12000 [==============================] - 11s 928us/step - loss: 0.3422 - accuracy: 0.9000\n",
      "Epoch 42/64\n",
      "12000/12000 [==============================] - 11s 921us/step - loss: 0.3343 - accuracy: 0.9001\n",
      "Epoch 43/64\n",
      "12000/12000 [==============================] - 11s 931us/step - loss: 0.3373 - accuracy: 0.8985\n",
      "Epoch 44/64\n",
      "12000/12000 [==============================] - 11s 926us/step - loss: 0.3423 - accuracy: 0.8978\n",
      "Epoch 45/64\n",
      "12000/12000 [==============================] - 11s 924us/step - loss: 0.3374 - accuracy: 0.9016\n",
      "Epoch 46/64\n",
      "12000/12000 [==============================] - 11s 932us/step - loss: 0.3422 - accuracy: 0.8989\n",
      "Epoch 47/64\n",
      "12000/12000 [==============================] - 11s 922us/step - loss: 0.3374 - accuracy: 0.8994\n",
      "Epoch 48/64\n",
      "12000/12000 [==============================] - 11s 936us/step - loss: 0.3266 - accuracy: 0.9026\n",
      "Epoch 49/64\n",
      "12000/12000 [==============================] - 11s 924us/step - loss: 0.3353 - accuracy: 0.8989\n",
      "Epoch 50/64\n",
      "12000/12000 [==============================] - 11s 922us/step - loss: 0.3431 - accuracy: 0.9005\n",
      "Epoch 51/64\n",
      "12000/12000 [==============================] - 11s 921us/step - loss: 0.3366 - accuracy: 0.9000\n",
      "Epoch 52/64\n",
      "12000/12000 [==============================] - 11s 940us/step - loss: 0.3439 - accuracy: 0.8976\n",
      "Epoch 53/64\n",
      "12000/12000 [==============================] - 12s 960us/step - loss: 0.3411 - accuracy: 0.8977\n",
      "Epoch 54/64\n",
      "12000/12000 [==============================] - 13s 1ms/step - loss: 0.3345 - accuracy: 0.9008\n",
      "Epoch 55/64\n",
      "12000/12000 [==============================] - 11s 928us/step - loss: 0.3328 - accuracy: 0.9011\n",
      "Epoch 56/64\n",
      "12000/12000 [==============================] - 11s 929us/step - loss: 0.3416 - accuracy: 0.8993\n",
      "Epoch 57/64\n",
      "12000/12000 [==============================] - 11s 939us/step - loss: 0.3444 - accuracy: 0.8972\n",
      "Epoch 58/64\n",
      "12000/12000 [==============================] - 11s 942us/step - loss: 0.3365 - accuracy: 0.8994\n",
      "Epoch 59/64\n",
      "12000/12000 [==============================] - 11s 923us/step - loss: 0.3343 - accuracy: 0.9009\n",
      "Epoch 60/64\n",
      "12000/12000 [==============================] - 11s 924us/step - loss: 0.3368 - accuracy: 0.9016\n",
      "Epoch 61/64\n",
      "12000/12000 [==============================] - 11s 925us/step - loss: 0.3397 - accuracy: 0.8980\n",
      "Epoch 62/64\n",
      "12000/12000 [==============================] - 11s 929us/step - loss: 0.3378 - accuracy: 0.8995\n",
      "Epoch 63/64\n",
      "12000/12000 [==============================] - 11s 922us/step - loss: 0.3424 - accuracy: 0.8994\n",
      "Epoch 64/64\n",
      "12000/12000 [==============================] - 11s 928us/step - loss: 0.3400 - accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc7ba2c3eb0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_vanilla_pooling.fit(train_images, train_labels, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate the model on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 793us/step - loss: 0.2087 - accuracy: 0.9391\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_vanilla_pooling.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Print the test accuracy. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9391000270843506\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate the model on the test data. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Print the test accuracy. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: More complex CNN with CIFAR-10\n",
    "\n",
    "As an extra part, you can also load the CIFAR-10 dataset, perform a similar data pre-processing as the MNIST dataset and implement a proper CNN. In this case, the dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. Therefore you will need a network that is a little bit deeper, with 4 convolution layer. \n",
    "\n",
    "This part is not guided as the previous one, it's up to you to start from scratch and try out the implementation. However the procduere is pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28,1).astype('float32')\n",
    "train_images /=255\n",
    "test_images /=255\n",
    "train_labels = to_categorical(train_labels,10)\n",
    "test_labels = to_categorical(test_labels,10)\n",
    "\n",
    "model_vanilla_pooling = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model_vanilla_pooling.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla_pooling.add(Flatten())\n",
    "model_vanilla_pooling.add(Dense(128))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "    \n",
    "# More Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.5))\n",
    "\n",
    "# Fully Connected Layer for Prediction\n",
    "model_vanilla_pooling.add(Dense(10))\n",
    "model_vanilla_pooling.add(Activation('softmax'))\n",
    "\n",
    "model_vanilla_pooling.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_vanilla_pooling.fit(train_images, train_labels, epochs, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_vanilla_pooling.fit(train_images, train_labels, epochs, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_vanilla_pooling.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10, 10, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
